package lexar

import (
	"fmt"

	"github.com/codecrafters-io/interpreter-starter-go/app/pkg/token"

	"strconv"
)

type Lexar struct {
	input []byte
	index int
	start int
	line  int
}

func (l *Lexar) eof() bool {
	return l.index >= len(l.input)
}

func (l *Lexar) next() byte {
	char := l.peek()
	l.index++
	return char
}

func (l *Lexar) peek() byte {
	if l.eof() {
		return 0
	}
	return l.input[l.index]
}

func (l *Lexar) peekNext() byte {
	if l.index+1 >= len(l.input) {
		return 0
	}
	return l.input[l.index+1]
}

func NewLexar(input []byte) *Lexar {
	return &Lexar{
		input: input,
		index: 0,
		line:  1,
	}
}

func (l *Lexar) match(expected byte) bool {
	isMatch := l.peek() == expected
	if isMatch {
		l.index++
	}

	return isMatch
}

func isNumber(char byte) bool {
	return char >= '0' && char <= '9'
}

func (l *Lexar) NextToken() token.Token {
	l.start = l.index
	inputChar := l.next()
	currToken := token.Token{}
	switch inputChar {
	case '(':
		currToken.TokenType = token.LeftParen
	case ')':
		currToken.TokenType = token.RightParen
	case '{':
		currToken.TokenType = token.LeftBrace
	case '}':
		currToken.TokenType = token.RightBrace
	case '*':
		currToken.TokenType = token.Star
	case '+':
		currToken.TokenType = token.Plus
	case ',':
		currToken.TokenType = token.Comma
	case '.':
		currToken.TokenType = token.Dot
	case '-':
		currToken.TokenType = token.Minus
	case ';':
		currToken.TokenType = token.Semicolon
	case '\n':
		l.line++
		return l.NextToken()
	case '=':
		currToken.TokenType = token.Equal
		if l.match('=') {
			currToken.TokenType = token.EqualEqual
		}
	case '!':
		currToken.TokenType = token.Bang
		if l.match('=') {
			currToken.TokenType = token.BangEqual
		}
	case '>':
		currToken.TokenType = token.Greater
		if l.match('=') {
			currToken.TokenType = token.GreaterEqual
		}
	case '<':
		currToken.TokenType = token.Less
		if l.match('=') {
			currToken.TokenType = token.LessEqual
		}
	case '\t', ' ', '\r':
		return l.NextToken()
	case '"':
		for l.peek() != '"' && !l.eof() {
			l.next()
		}
		currToken.TokenType = token.StringToken
		currToken.Literal = string(l.input[l.start+1 : l.index])

		if l.peek() != '"' {
			currToken.TokenType = token.ErrorToken
			currToken.Literal = fmt.Errorf("[line %d] Error: Unterminated string.", l.line)
		}
		l.next()

	case '/':
		if l.match('/') {
			for l.peek() != '\n' && !l.eof() {
				// skip comments
				l.next()
			}
			return l.NextToken()
		}
		currToken.TokenType = token.Slash
	case 0:
		currToken.TokenType = token.Eof
		return currToken
	default:
		if isNumber(inputChar) {
			tokenType, literal := l.parseNumber()
			currToken.TokenType = tokenType
			currToken.Literal = literal

		} else if isAlpha(inputChar) {
			for isAlphaNumeric(l.peek()) {
				l.next()
			}
			if val, ok := token.ReservedKeywords[string(l.input[l.start:l.index])]; ok {
				currToken.TokenType = val
			} else {
				currToken.TokenType = token.Identifier
			}
		} else {
			currToken.TokenType = token.ErrorToken
			currToken.Literal = fmt.Errorf("[line %d] Error: Unexpected character: %v", l.line, string(inputChar))
		}
	}

	currToken.Lexeme = string(l.input[l.start:l.index])

	return currToken

}
func (l *Lexar) Scan() ([]token.Token, []error) {
	tokens := []token.Token{}
	errorArr := []error{}
	currToken := l.NextToken()
	for currToken.TokenType != token.Eof {
		if currToken.TokenType == token.ErrorToken {
			errorArr = append(errorArr, currToken.Literal.(error))
		} else {
			tokens = append(tokens, currToken)
		}
		currToken = l.NextToken()
	}

	tokens = append(tokens, token.Token{TokenType: token.Eof, Lexeme: ""})

	return tokens, errorArr
}

func isAlphaNumeric(char byte) bool {
	return isAlpha(char) || isNumber(char)
}

func isAlpha(char byte) bool {
	return (char >= 'a' && char <= 'z') || (char >= 'A' && char <= 'Z') || char == '_'
}

func (l *Lexar) parseNumber() (token.TokenType, interface{}) {
	for isNumber(l.peek()) {
		l.next()
	}

	if l.peek() == '.' && isNumber(l.peekNext()) {
		l.next()

		for isNumber(l.peek()) {
			l.next()
		}
	} else {
		valInt64, _ := strconv.ParseInt(string(l.input[l.start:l.index]), 10, 64)
		return token.NumberInt, valInt64
	}

	// dont need to handle error we check validate it above
	num, _ := strconv.ParseFloat(string(l.input[l.start:l.index]), 64)

	return token.NumberFloat, num
}
